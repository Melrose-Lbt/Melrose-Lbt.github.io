


<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>  【动手开发深度学习框架日记】Tensor基本数据结构 |    white.</title>
  <meta name="description" content="A minimalist theme for hexo.">
  <!-- 标签页图标 -->
  

  <!-- 图标库 -->
  <link href="https://cdn.jsdelivr.net/npm/remixicon@2.2.0/fonts/remixicon.css" rel="stylesheet">
  <!-- 动画库 -->
  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/fushaolei/cdn-white@1.0/css/animate.css"/>
  
  <!-- css文件 -->
  
<link rel="stylesheet" href="/css/white.css">

  <!-- 代码高亮 -->
  
    
      
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10.1.1/styles/github.css">

    
  
<meta name="generator" content="Hexo 6.3.0"></head>


<body>

<div class="menu-outer">
    <div class="menu-inner">
      <div class="menu-site-name  animate__animated  animate__fadeInUp">
        <a href="/">
          white.
        </a>
        
      </div>
      <div class="menu-group">
        <ul class="menu-ul">
        
          <a href="/" class="nav-link">
            <li class="menu-li  animate__animated  animate__fadeInUp">
              HOME
            </li>
          </a>
        
          <a href="/archives" class="nav-link">
            <li class="menu-li  animate__animated  animate__fadeInUp">
              BLOG
            </li>
          </a>
        
        
          <li class="menu-li animate__animated  animate__fadeInUp" id="sort">
             分类
             <div class="categories-outer " id="sort-div">
               <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/CUDA-Programming/">CUDA Programming</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Diary/">Diary</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Neutron/">Neutron</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Paper-reading-note/">Paper reading note</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Source-Code-Reading-Note/">Source Code Reading Note</a></li></ul>
             </div>
          </li>
        
        
          <li class="menu-li animate__animated  animate__fadeInUp" id="mobile-menu">
            <i class="ri-menu-line"></i>
          </li>
        
        </ul>

      </div>

    </div>
</div>
<div id="mobile-main" class="animate__animated  animate__fadeIn">
  <div class="mobile-menu-inner">
    <div class="mobile-menu-site-name animate__animated  animate__fadeInUp">
      <a href="/">
        white.
      </a>
    </div>
    <div class="mobile-menu-group" id="mobile-close">
      <i class="ri-close-line"></i>
    </div>

  </div>

  <div class="mobile-menu-div">
  
    <a href="/" class="mobile-nav-link">
      <div class="mobile-menu-child animate__animated  animate__fadeInUp">
        <span>HOME</span>
      </div>
    </a>
  
    <a href="/archives" class="mobile-nav-link">
      <div class="mobile-menu-child animate__animated  animate__fadeInUp">
        <span>BLOG</span>
      </div>
    </a>
  
  
  </div>


</div>

<div class="body-outer">
  <div class="body-inner">
    
<article class="post-inner">
  <div class="post-content-outer">
    <div class="post-intro">
      <div class="post-title animate__animated  animate__fadeInUp">【动手开发深度学习框架日记】Tensor基本数据结构</div>
      <div class="meta-intro animate__animated  animate__fadeInUp">Oct 15 2022</div>
      
        <div class="post-cover"><span class="lazyload-img-span"><img data-src="/image/cover/NeutronLogo.png" class="post-cover-img"></span></div>
      
    </div>
    <div class="post-content-inner">
      <div class="post-content-inner-space">

      </div>
      <div class="post-content-main animate__animated  animate__fadeInUp">
        <!-- top型目录 -->
        
        <blockquote>
<p>我的专业是智能科学与技术专业，硬件软件方面的知识都有涉及一些。深度学习技术在我学习生涯中占比例是很大的。虽然学习过一些机器学习、神经网络等一些理论基础，但是用别人成熟的框架总感觉缺失点东西。以学习出发为目的，我花了一两个月时间使用Numpy+Python写了第一个自己的深度学习框架MetaFlow，实现了Tensor、反向传播、自动微分算子、Dataset、DataLoader等模块，使用起来类似于Pytorch，但是由于学习种种原因就被搁置了，仅仅实现了全连接神经网络的封装。同时MetaFlow还有一个缺点就是没有使用GPU加速。CUDA程序设计也是我比较期待学习的。所以产生了写一个基于CUDA/C为后端，Python为前端的简单的深度学习框架。这次的目标主要是实现全连接以及卷积操作，并提供类似于Pytorch的接口，同时支持batch训练、模型保存等等功能。<br>这个系列的博客用于个人学习记录，同时把一些实现的方法分享出来，也算是项目的参考文档。</p>
</blockquote>
<h1 id="一、数据结构的定义"><a href="#一、数据结构的定义" class="headerlink" title="一、数据结构的定义"></a>一、数据结构的定义</h1><p><strong>张量</strong>（<strong>Tensor</strong>）是在任何深度学习框架中最为重要的一个数据结构。该数据结构需要实现以下几个功能：</p>
<blockquote>
<ul>
<li><strong>支持高维度矩阵的运算</strong></li>
<li><strong>允许记录梯度值，且可以设置是否需要求梯度</strong></li>
<li><strong>作为计算图中的结点可以记录父节点和子节点</strong></li>
<li><strong>可以记录得到该结点时运用了哪些算子</strong></li>
<li><strong>能够做到数据从CPU（host）到GPU（device）的转换和创建</strong></li>
<li><strong>支持反向传播算法</strong></li>
</ul>
</blockquote>
<p>这里需要关注的就是CPU到GPU数据的转换和格式如何去定义。</p>
<h4 id="1-1-CPU数据结构和GPU数据结构"><a href="#1-1-CPU数据结构和GPU数据结构" class="headerlink" title="1.1 CPU数据结构和GPU数据结构"></a>1.1 CPU数据结构和GPU数据结构</h4><p>我采取了两种基本数据类型，分别时Numpy数组（CPU端计算）以及Quark（GPU端计算），Tensor在这里的作用更像是管理者和资源记录分配者，而真正需要进行数据运算的是上面二位基本数据结构支持的。Quark也叫夸克（项目名称是Neutron，中文是中子的意思，为了战术上的统一就给后端的数据结构起了名字叫夸克），是定义在后端的结构体。具体实现的代码如下：</p>
<pre><code class="lang-cpp">extern &quot;C&quot;&#123;
    typedef enum&#123;
        CPU = 0,
        GPU = 1
    &#125;Device;

    typedef struct&#123;
        float* data;
        Device device;
        int* shape;
        int dim;
    &#125;Quark;
&#125;
</code></pre>
<p>代码定义在 _array.h_ 头文件当中，其中包含float型数据指针；enum类型Device判断是使用CPU计算数据还是GPU；同样是数组指针shape，用于记录张量形状；以及dim记录张量维数。这些是在CUDA程序中十分重要的几个参数。</p>
<p>为了能够使C/C++的API供Python调用，使用了Python内置的ctypes库。那么在Python端，将CUDA/C++编译好的动态链接库文件导入，就可以使用后端的数据结构和API了。关于混合编程以及接口调用的问题，会在另一个文章里记录说明（<strong>未更新</strong>）。</p>
<p>总之，Quark结构体映射至Python代码中的实现如下：</p>
<pre><code class="lang-python">class Quark(ctypes.Structure):
    &quot;&quot;&quot;
        C++ back-end data structure. Contains data pointer (numpy data type has to
        be float32, otherwise it&#39;ll raise calculate error), device, data shape poin
        ter and dimension.
    &quot;&quot;&quot;
    _fields_ = [(&#39;data&#39;, ctypes.POINTER(c_float)),
                (&#39;device&#39;, ctypes.c_int),
                (&#39;shape&#39;, ctypes.POINTER(ctypes.c_int)),
                (&#39;dim&#39;, ctypes.c_int)]
</code></pre>
<p>关于使用CPU计算的数据就很简单了，np.array()就完事儿，什么shape，dim都能获取到。</p>
<h4 id="1-2-Tensor定义"><a href="#1-2-Tensor定义" class="headerlink" title="1.2 Tensor定义"></a>1.2 Tensor定义</h4><p>之前提到过，Tensor在框架中的角色其实并不是计算，而是充当一个资源调度和管理的角色。那么它就要能集两家之数据（CPU和GPU），无缝的、信息不丢失的衔接切换。同时还要实现什么梯度记录呀、父子结点记录呀、反向传播算法等等功能。当然要实现数据到GPU还是需要一些CUDA代码的，本篇日记仅仅记录实现逻辑，背后的CUDA代码会在另一个记录中说明（<strong>未更新</strong>）。</p>
<p>首先定义一个类，Tensor类，类中的属性就可以按照我们的需求来</p>
<pre><code class="lang-python">class Tensor:
    &quot;&quot;&quot;
        Python fore-end data structure.
        The most important attr is handle. Handle is a pointer to the real data str
        -ucture. It manages GPU data structure (Quark) and CPU data structure (numpy).

        When you instantiate the Tensor, you need to give parameters as follows:
        1. data: numpy array, dtype is np.float32.
        2. device: on cpu or on gpu.
        3. require_grad: require calculate gradient or not.
    &quot;&quot;&quot;

    def __init__(self, data, device=CPU, require_grad=False):
        self.children = []
        self.father = []
        self.op = None
        self.grad = None
        self.device = device
        self.require_grad = require_grad
        self.handle = self.configureHandle(self, data, device)
</code></pre>
<p>里面包括父子结点列表、op算子、梯度、设备（CPU/GPU）、求梯度标志位、数据结构句柄。这个handle的作用就是根据device属性来判别需要创建什么句柄。</p>
<p>这里涉及到类的函数，<code>self.configureHandle()</code>，实现如下：</p>
<pre><code class="lang-python">    @staticmethod
    # configure the handle attribute
    def configureHandle(self, data, device):
        if isinstance(data, tuple):
            data = np.random.random(data)
        if device == GPU:
            return self.getQuarkHandle(data.astype(np.float32))
        elif device == CPU:
            return self.getNumpyHandle(data.astype(np.float32))

    @staticmethod
    # get the Quark data structure handle
    def getQuarkHandle(numpy_data):
        assert isinstance(numpy_data, ndarray), &quot;input data should be numpy array&quot;
        data = numpy_data
        arr = Quark()
        arr.data = data.ctypes.data_as(ctypes.POINTER(c_float))
        arr.device = GPU
        arr.shape = getShape(ctypes.c_int, data.shape)
        arr.dim = len(data.shape)

        # start to allocate and copy data to GPU
        size = CUDALib.getSize(arr.dim, arr.shape)
        dev_ptr = CUDALib.AllocateDeviceData(size)
        CUDALib.CopyDataFromTo(arr.data, dev_ptr, CPU, GPU, size)
        arr.data = dev_ptr
        return arr

    @staticmethod
    # get the numpy data structure handle4
    def getNumpyHandle(numpy_data):
        assert isinstance(numpy_data, ndarray), &quot;input data should be numpy array&quot;
        return numpy_data
</code></pre>
<pre><code>首先判断要在CPU计算还是GPU计算，分别转到`getNumpyHandle()`和`getQuarkHandle()`。第一个函数实现很简单，返回numpy数组即可。`getQuarkHandle()`首先要从numpy数据中获取想要的信息，实例化Quark，在根据Quark的信息调用后端实现CUDA内存分配代码，把数据直接加载到GPU显存上。最后返回Quark实例化数据。

为了方便观察和调试，需要提供一些数据获取的接口。

```python
    @property
    def shape(self):  # get data shape
        if isinstance(self.handle, ndarray):
            return self.handle.shape
        return tuple([self.handle.shape[idx] for idx in range(self.handle.dim)])

    @property
    def data(self):  # get data
        assert(self.device == GPU), &quot;the data on the gpu instead of cpu&quot;
        return np.ctypeslib.as_array(self.handle.data, shape=self.shape)

    def __str__(self):

        return &quot;Tensor(&#123;&#125;, shape=&#123;&#125;, dtype=Tensor.float32)&quot;.format(np.ctypeslib.as_array(self.handle.data, shape=self.shape), self.shape)
</code></pre><p>和Pytorch类似，转移Tensor数据时，只需要xx.cpu()或者xx.gpu()即可。具体代码如下：</p>
<pre><code class="lang-python">    # transfer the data from the gpu to the cpu
    def cpu(self):
        if self.device == GPU:
            size = CUDALib.getSize(self.handle.dim, self.handle.shape)
            host_ptr = CUDALib.AllocateHostData(size)
            CUDALib.CopyDataFromTo(self.handle.data, host_ptr, GPU, CPU, size)
            self.handle.data = host_ptr
        return self

    # transfer the data from the cpu to the gpu
    def gpu(self):
        if self.device == CPU and isinstance(self.handle, ndarray):
            self.handle = self.getQuarkHandle(self.handle)
            self.device = GPU
        return self
</code></pre>
<p><code>gpu()</code>实现的逻辑就调用了<code>getQuarkHandle()</code>创建一个GPU的Quark。<code>cpu()</code>则需要利用CUDA的API将GPU显存数据移动到CPU上。</p>
<p>对于反向传播方法和剩余的方法将分布在其他文章中解释（<strong>未更新</strong>）。</p>
<h1 id="二、使用例程"><a href="#二、使用例程" class="headerlink" title="二、使用例程"></a>二、使用例程</h1><p>使用Tensor，可以预先创建numpy数组，前提 <strong>必须</strong> 数据是 <strong>np.float32</strong> 类型。这是因为在后端定义Quark是float类型，如果采用其他数据类型GPU运算出的数据会千奇百怪（如果忘记也没有关系，代码中会自动将类型变为float32）。<br>首先，可以使用numpy创建任意维度的数组，然后通过Tensor进一步封装。</p>
<pre><code class="lang-python">x = np.ones((64, 64))
xt = Tensor(x, CPU, require_grad=False)
print(xt)

# console results
Tensor([[1. 1. 1. ... 1. 1. 1.]
 [1. 1. 1. ... 1. 1. 1.]       
 [1. 1. 1. ... 1. 1. 1.]       
 ...
 [1. 1. 1. ... 1. 1. 1.]
 [1. 1. 1. ... 1. 1. 1.]
 [1. 1. 1. ... 1. 1. 1.]], shape=(64, 64), dtype=Tensor.float32)
</code></pre>
<p>我们可以通过调用<code>cpu()</code>和<code>gpu()</code>转移Tensor。</p>
<pre><code class="lang-python">xt.cpu()
xt.gpu()
</code></pre>
<p>值得注意的是，若想要打印数据，必须调用<code>cpu()</code>把数据移动到CPU来。<br>也可以通过输入元组数据，Tensor会自动创建基于正态分布的随机张量。</p>
<pre><code class="lang-python">xt = Tensor((1, 64, 64), CPU, require_grad=False)
print(xt)

# console results
Tensor([[[0.43749017 0.29031968 0.8365907  ... 0.61214393 0.44423762 0.03210686]
  [0.6642815  0.7885864  0.6017005  ... 0.28682867 0.49431917 0.64389694]
  [0.02547996 0.5165705  0.711713   ... 0.33360547 0.13552403 0.6047031 ]
  ...
  [0.5312942  0.13073258 0.39996797 ... 0.3393874  0.38398758 0.81480604]
  [0.08465459 0.855784   0.6820476  ... 0.10212806 0.11926474 0.6199378 ]
  [0.92551076 0.92917097 0.8674459  ... 0.34977752 0.55820996 0.50206757]]], shape=(1, 64, 64), dtype=Tensor.float32)
</code></pre>
<p>以上就是目前数据结构的全部内容啦，当然会随着开发的完善逐步更新这个博客。感谢阅读！</p>

        <!-- 分类文章 -->
        
          <div class="post-categoris-bottom">
            <div class="post-categoris-name">Neutron</div>
            <ul>
            
            
              
            
            
            
              
                <li class="me base">
                  <a  href="/2022/10/15/%E3%80%90%E5%8A%A8%E6%89%8B%E5%BC%80%E5%8F%91%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6%E6%97%A5%E8%AE%B0%E3%80%91Tensor%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" class="post-categoris-bottom-link">
                  【动手开发深度学习框架日记】Tensor基本数据结构
                </a>
                </li>
              
              
            
            
            
              
            
            
            
              
            
            
            
              
            
            
            
              
            
            
            
              
                <li class="base">
                  <a  href="/2022/10/15/%E3%80%90%E5%8A%A8%E6%89%8B%E5%BC%80%E5%8F%91%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6%E6%97%A5%E8%AE%B0%E3%80%91GPU%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86API/" class="post-categoris-bottom-link">
                  【动手开发深度学习框架日记】GPU内存管理API
                </a>
                </li>
              
              
            
            
            
              
            
            
            
              
            
            
            </ul>

          </div>

        
      </div>
      <div class="post-content-inner-space">
        
      </div>
   </div>
    <!-- 评论 -->
    
  </div>
</article>
  </div>
</div>



<!-- 如果是home模式的话，不在首页就显示footer，如果不是home模式的话 所有都显示footer -->

  <div class="footer-outer animate__animated  animate__fadeInUp">
    <div class="footer-inner">
    <div class="footer-text">
    <p>Power by <a target="_blank" rel="noopener" href="http://hexo.io/">Hexo</a> Theme by <a target="_blank" rel="noopener" href="https://github.com/FuShaoLei/hexo-theme-white">White</a></p>

    </div>
    <div class="footer-contact">
    <ul class="footer-ul">
        
        <li class="footer-li">
            <a href="https://github.com/FuShaoLei/hexo-theme-white" target="_blank">
                <i class="ri-github-line"></i>
            </a>
        </li>
        
        <li class="footer-li">
            <a href="mailto:1563250958@qq.com" target="_blank">
                <i class="ri-mail-line"></i>
            </a>
        </li>
        
    </ul>
    </div>
    </div>
</div>






<script src="/js/white.js"></script>



    
      
<script src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.18.1/build/highlight.min.js"></script>

      <script>hljs.initHighlightingOnLoad();</script>
    

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>
